{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1ce29fb-a571-45ca-9466-5ff4ce3a48a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "################################\n",
    "# General Imports\n",
    "################################\n",
    "import csv, math, io, os, os.path, sys, random, time, json, gc, glob, statistics\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "from joblib import Parallel, delayed, dump, load\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "################################\n",
    "# Scientific Imports\n",
    "################################\n",
    "import scipy\n",
    "from scipy.signal import butter,filtfilt\n",
    "\n",
    "################################\n",
    "# SKLearn Imports\n",
    "################################\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "################################\n",
    "# SKTime Imports\n",
    "################################\n",
    "from sktime.datatypes._panel._convert import from_2d_array_to_nested, from_nested_to_2d_array, is_nested_dataframe, from_nested_to_multi_index\n",
    "#from sktime.forecasting.compose import TransformedTargetForecaster\n",
    "#from sktime.forecasting.model_selection import ForecastingGridSearchCV\n",
    "\n",
    "from sktime.datasets import load_arrow_head\n",
    "\n",
    "from sktime.registry import all_estimators\n",
    "\n",
    "from sktime.classification.kernel_based import Arsenal\n",
    "#from sktime.classification.interval_based import CanonicalIntervalForest\n",
    "#from sktime.classification.dictionary_based import ContractableBOSS\n",
    "#from sktime.classification.interval_based import DrCIF\n",
    "#from sktime.classification.hybrid import HIVECOTEV1\n",
    "#from sktime.classification.dictionary_based import IndividualBOSS\n",
    "#from sktime.classification.dictionary_based import IndividualTDE\n",
    "#from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "#from sktime.classification.feature_based import MatrixProfileClassifier\n",
    "#from sktime.classification.dictionary_based import MUSE\n",
    "#from sktime.classification.interval_based import RandomIntervalSpectralForest\n",
    "#from sktime.classification.distance_based import ShapeDTW\n",
    "#from sktime.classification.feature_based import SignatureClassifier\n",
    "#from sktime.classification.interval_based import SupervisedTimeSeriesForest\n",
    "#from sktime.classification.feature_based import TSFreshClassifier\n",
    "#from sktime.classification.dictionary_based import WEASEL\n",
    "\n",
    "################################\n",
    "# Initialisers\n",
    "################################\n",
    "default_rc_params = (16,9)\n",
    "plt.rcParams[\"figure.figsize\"] = default_rc_params\n",
    "sb.set()\n",
    "\n",
    "xNaNs = np.load(\"X_NAN_LIST.npy\")\n",
    "xTime = np.load(\"X_TIME_LIST.npy\")\n",
    "ESTIM = all_estimators(estimator_types=\"classifier\")\n",
    "\n",
    "################################\n",
    "# Suppress Warnings\n",
    "################################\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b1ada2-2bbf-4bfc-ad27-3572cce5441d",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c90789e3-26c8-4a18-a0a4-742578c3ebf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################################\n",
    "# Functions\n",
    "################################\n",
    "\n",
    "def Every_Nth_Value(y,nth=40):\n",
    "    \n",
    "    newY = np.zeros(len(y))\n",
    "    \n",
    "    print(\"Every Nth Value\")\n",
    "    \n",
    "    for row in y:\n",
    "        #row[:] = row[::nth]\n",
    "        row = np.delete(row, np.arange(None, None, nth))\n",
    "    \n",
    "    return y\n",
    "\n",
    "################################\n",
    "\n",
    "def Every_Nth_ValueXY(x,y,n=40):\n",
    "    return (Every_Nth_Value(x,nth=n), Every_Nth_Value(y,nth=n))\n",
    "\n",
    "################################\n",
    "\n",
    "def EveryNthNested(y,nth=40):\n",
    "    print(\"Every Nth Value (NESTED)\")\n",
    "    \n",
    "    if type(y) is not np.ndarray:\n",
    "        print(f\"Datatype {type(y)} found! Processing...\")\n",
    "        # De-nest\n",
    "        y_ = from_nested_to_2d_array(y,True)\n",
    "\n",
    "        # Subsample\n",
    "        y_ = y[::nth]\n",
    "\n",
    "        # Re-nest\n",
    "        y_ = from_2d_array_to_nested(y_)\n",
    "    else:\n",
    "        print(\"np array detected; returning as-is\")\n",
    "        y_ = y\n",
    "    # Return\n",
    "    print(\"Returning\")\n",
    "    return y_\n",
    "\n",
    "################################\n",
    "\n",
    "def GetNumDays(time=xTime):\n",
    "    \n",
    "    #xTime = np.load(\"X_TIME_LIST.npy\")\n",
    "    nDays = time[-1]-time[0]\n",
    "    \n",
    "    return (nDays)\n",
    "\n",
    "################################\n",
    "\n",
    "def FilterMyData(x,cutoff=0.00005,order=2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to apply a Butter Filter to timeseries.\n",
    "    Vars:\n",
    "    \n",
    "    y:        The timeseries. Must be list or np array.\n",
    "    cutoff:   The cutoff frequency. Used to determine where the filter cut off is.\n",
    "    order:    Approximation via polynomial of the order'th degree (2=quadratic, 3=cubic, 4=quartic, etc)\n",
    "    \"\"\"\n",
    "    \n",
    "    # DATA VALIDATION\n",
    "    # Flag\n",
    "    isNested = False\n",
    "    \n",
    "    print(f\"INITIAL shape of x is {x.shape}; INITIAL type of x is {type(x)}\")\n",
    "    \n",
    "    # Check to see if x is a nested dataframe or not\n",
    "    if type(x) == pd.core.frame.DataFrame:\n",
    "        isNested = True\n",
    "        print(\"NESTED DATAFRAME FOUND! UNPACKING...\")\n",
    "        x = from_nested_to_2d_array(x,True)\n",
    "    \n",
    "    # First, let's calculate the observational time period;\n",
    "    # This is done separately so that I can change this in the future for any TESS fits file\n",
    "    numdays       = GetNumDays()\n",
    "    \n",
    "    # Next, fix data                           \n",
    "    xMedian       = np.median(x)                                                    # Get the median value of 'x' before changing it\n",
    "    x             = [xMedian if n in xNaNs else item for n,item in enumerate(x)]    # Change all the missing values to the median value of the whole array\n",
    "    \n",
    "    # Frequency Data Stuff\n",
    "    sec           = numdays*24*60*60   # Number of seconds in the overall observation period\n",
    "    freq          = len(x)/sec         # Frequency, in Hz, ie number of observations per second\n",
    "    # FREQ IS APPROX 1/120 OR ~0.008333333\n",
    "    \n",
    "    # Butter Lowpass Filter\n",
    "    #polynomOrder  = order\n",
    "    nyq           = 0.5 * freq\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    #b, a          = butter(polynomOrder, normal_cutoff, btype='low', analog=False)\n",
    "    b, a          = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    \n",
    "    newX          = np.array(filtfilt(b, a, x))\n",
    "    \n",
    "    print(f\"newX generated; curr shape is {newX.shape} and current dtype is {newX.dtype}\")\n",
    "    \n",
    "    if isNested == True:\n",
    "        newX = np.vstack(newX[:,]).astype('float32')   # <-- This apparently fixes some of the issues I've been having?\n",
    "        # see: https://stackoverflow.com/questions/19459017/how-to-convert-a-numpy-2d-array-with-object-dtype-to-a-regular-2d-array-of-float\n",
    "        \n",
    "        newX = from_2d_array_to_nested(newX)\n",
    "    \n",
    "    print(f\"Returning Values; final shape is {newX.shape} and final type is {type(newX)}\")\n",
    "    \n",
    "    # Finally, return the new X and Y values\n",
    "    return (newX)\n",
    "\n",
    "################################\n",
    "\n",
    "def FilterMyUnNestedData(x,cutoff=0.00005,order=2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to apply a Butter Filter to timeseries.\n",
    "    Vars:\n",
    "    \n",
    "    y:        The timeseries. Must be list or np array.\n",
    "    cutoff:   The cutoff frequency. Used to determine where the filter cut off is.\n",
    "    order:    Approximation via polynomial of the order'th degree (2=quadratic, 3=cubic, 4=quartic, etc)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # First, let's calculate the observational time period;\n",
    "    # This is done separately so that I can change this in the future for any TESS fits file\n",
    "    numdays = GetNumDays()\n",
    "    sec     = numdays*24*60*60   # Number of seconds in the overall observation period\n",
    "    rowLen  = len(x[0])          # Technically bad practice, bu since we know every row has same length, it's okay to do outside func\n",
    "    freq    = rowLen/sec         # Frequency, in Hz, ie number of observations per second\n",
    "    \n",
    "    # Butter Lowpass Filter\n",
    "    #polynomOrder  = order\n",
    "    nyq           = 0.5 * freq\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    \n",
    "    for row in x:\n",
    "\n",
    "        # Next, fix data                           \n",
    "        ####rowMedian = np.median(row)                                                    # Get the median value of 'x' before changing it\n",
    "        ####print(f\"Median is {rowMedian}\")\n",
    "        ####row[...]  = [rowMedian if n in xNaNs else item for n,item in enumerate(row)]    # Change all the missing vals to median of the whole row\n",
    "        row       = FIXNAN(row)\n",
    "        \n",
    "        b, a      = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "        row       = np.array(filtfilt(b, a, x))\n",
    "    \n",
    "    # Finally, return the new X and Y values\n",
    "    return (x)\n",
    "\n",
    "################################\n",
    "\n",
    "def Normalise(X,fixnan=True):\n",
    "    # First of all, decide if wan to Fix all the 0s / NaNs\n",
    "    if fixnan:\n",
    "        X = FIXNANNEW(X)\n",
    "\n",
    "    median = np.median(X)\n",
    "\n",
    "    #print(f\"OldNormal median = {median}\")\n",
    "\n",
    "    X[:] = [(number/median) for number in X]\n",
    "    return X\n",
    "\n",
    "################################\n",
    "\n",
    "def FIXNANNEW(y, nanList=xNaNs):\n",
    "    \n",
    "    print(f\"Array has [{len(y)}] elements, with each element having [{len(y[0])}] sub-elements\")\n",
    "    \n",
    "    for row in y:\n",
    "        m = np.median(row)\n",
    "        #print(f\"median = {m}\")\n",
    "        row[...] = [m if n in nanList else item for n,item in enumerate(row)]\n",
    "    \n",
    "    return y\n",
    "\n",
    "################################\n",
    "\n",
    "def FIXNAN(y, nanList=xNaNs):\n",
    "    yMedian = np.median(y)\n",
    "    y = [yMedian if n in nanList else item for n,item in enumerate(y)]\n",
    "    return y\n",
    "\n",
    "################################\n",
    "\n",
    "def ConvertDataToNestedDF(X):\n",
    "    print(f\"Shape of X is {X.shape}\")\n",
    "    x = from_2d_array_to_nested(X)\n",
    "    return x\n",
    "\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "839dd5d5-6637-48a3-abe5-4db65fd3051c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def StretchArray(oldArr):\n",
    "    \n",
    "    q = np.zeros(2*len(oldArr)-1)\n",
    "    q[0]  = oldArr[0]\n",
    "    q[-1] = oldArr[-1]\n",
    "\n",
    "    for i in range(len(n)):\n",
    "        #print(f\"X[{i}] = {n[i]}\")\n",
    "\n",
    "        if i != len(oldArr)-1:\n",
    "\n",
    "            q[2*i]   = oldArr[i]\n",
    "            q[2*i+1] = np.average([oldArr[i],oldArr[i+1]])\n",
    "    \n",
    "    return q\n",
    "    \n",
    "    #q[i]   = X[0][i//2]\n",
    "    #q[i+1] = 0.5*(X[0][i] + X[0][i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f527a37-82ba-4c42-b32b-03f052b7414a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = fetch_california_housing(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "78a957dd-504e-4155-b20f-21136d049866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 20640)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "53a27a7c-28eb-456f-aca8-89ed4f3ca5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "flt = FunctionTransformer(FilterMyUnNestedData)\n",
    "nth = FunctionTransformer(Every_Nth_Value)\n",
    "nrm = FunctionTransformer(Normalise)\n",
    "cnv = FunctionTransformer(ConvertDataToNestedDF)\n",
    "\n",
    "pipe = Pipeline(steps=[('filter',flt),('everynth',nth),('normalise', nrm),('recombine', cnv), ('algorithm',Arsenal())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075c816f-2184-4e11-b02b-57c192237402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d6281f-417b-4fa2-8fb9-87a836fcaa17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
