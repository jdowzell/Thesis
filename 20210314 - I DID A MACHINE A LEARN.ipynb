{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "################################\n",
    "# Scientific imports\n",
    "###\n",
    "%matplotlib inline\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astroquery.mast import Observations\n",
    "from astroquery.mast import Catalogs\n",
    "\n",
    "###\n",
    "# General imports\n",
    "###\n",
    "import csv, math, io, os, os.path, sys, random, time\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from IPython.display import display\n",
    "\n",
    "###\n",
    "# Time imports\n",
    "###\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "###\n",
    "# MatPlotLib Settings\n",
    "###\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,9)\n",
    "sb.set()\n",
    "\n",
    "###\n",
    "# Global Variables\n",
    "###\n",
    "# Lists\n",
    "fitsList=[]\n",
    "starlist=[]\n",
    "planetlist=[]\n",
    "eblist=[]\n",
    "beblist=[]\n",
    "dataset = pd.DataFrame(columns=['id', 'vals', 'isplanet'])\n",
    "\n",
    "# List Holder\n",
    "alllists = {}\n",
    "\n",
    "# Keep track of current LC and it's TIC identifier\n",
    "lastRandom={\n",
    "    \"number\": 0,\n",
    "    \"id\": 0\n",
    "}\n",
    "\n",
    "################################\n",
    "# Functions\n",
    "###\n",
    "# Function for Reading which LC datafiles we have into a list\n",
    "def MakingAList(prnt=False):\n",
    "    fl = []\n",
    "    fitsroot = \"SIM_DATA/\"\n",
    "    fits_directories = [x[0] for x in os.walk('./SIM_DATA/.', topdown=True)]\n",
    "\n",
    "    for fitsroot, fits_dirs, fits_files in os.walk(fitsroot):\n",
    "        for fits_file in fits_files:\n",
    "            fullpath = os.path.join(fitsroot, fits_file)\n",
    "            if (os.path.splitext(fullpath.lower())[1]).endswith('.fits'):\n",
    "                fl.append(fullpath)\n",
    "    if prnt==True:\n",
    "        print(\"Number of FITS files: {}\".format(len(fl)))\n",
    "    #print(len(fl))\n",
    "    return fl\n",
    "\n",
    "# Chooses a random number\n",
    "def GetRandomLC(n = None):\n",
    "    global lastRandom\n",
    "    #print(\"1: {}\".format(n))\n",
    "    if isinstance(n, int):\n",
    "        if 0 <= n < len(fitsList):\n",
    "            n = n\n",
    "        else:\n",
    "            n = random.randint(0,len(fitsList))\n",
    "    else:\n",
    "        n = random.randint(0,len(fitsList))\n",
    "    \n",
    "    lastRandom[\"number\"] = n\n",
    "    lastRandom[\"id\"] = str(fitsList[n].split(\"-\")[2].lstrip(\"0\"))\n",
    "    return n\n",
    "\n",
    "def DrawACurve(n=None):\n",
    "    rndFile = GetRandomLC() if n == None else GetRandomLC(n)\n",
    "    fitsFile = fitsList[rndFile]\n",
    "    \n",
    "    # The following line of code gives us the header values\n",
    "    fitsHeaders = fits.getheader(fitsFile)\n",
    "\n",
    "    with fits.open(fitsFile, mode=\"readonly\") as hdulist:\n",
    "\n",
    "        # Extract stellar parameters from the primary header.  We'll get the effective temperature, surface gravity,\n",
    "        # and TESS magnitude.\n",
    "        star_teff = hdulist[0].header['TEFF']\n",
    "        star_logg = hdulist[0].header['LOGG']\n",
    "        star_tmag = hdulist[0].header['TESSMAG']\n",
    "        obj = hdulist[0].header['OBJECT']\n",
    "        sector = hdulist[0].header['SECTOR']\n",
    "\n",
    "        # Extract some of the fit parameters for the first TCE.  These are stored in the FITS header of the first\n",
    "        # extension.\n",
    "        #period = hdulist[1].header['TPERIOD']\n",
    "        #duration = hdulist[1].header['TDUR']\n",
    "        duration = (hdulist[1].header['LIVETIME'])\n",
    "        #epoch = hdulist[1].header['TEPOCH']\n",
    "        #depth = hdulist[1].header['TDEPTH']\n",
    "\n",
    "        # Extract some of the columns of interest for the first TCE signal.  These are stored in the binary FITS table\n",
    "        # in the first extension.  We'll extract the timestamps in TBJD, phase, initial fluxes, and corresponding\n",
    "        # model fluxes.\n",
    "        #times = hdulist[1].data['TIME']\n",
    "        #phases = hdulist[1].data['PHASE']\n",
    "        #fluxes_init = hdulist[1].data['LC_INIT']\n",
    "        #model_fluxes_init = hdulist[1].data['MODEL_INIT']\n",
    "        tess_bjds = hdulist[1].data['TIME']\n",
    "        sap_fluxes = hdulist[1].data['SAP_FLUX']\n",
    "        pdcsap_fluxes = hdulist[1].data['PDCSAP_FLUX']\n",
    "\n",
    "    # Define the epoch of primary transit in TBJD.  Our timestamps are also already in TBJD.\n",
    "    #t0 = 1327.520678\n",
    "\n",
    "    # Start figure and axis.\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot the timeseries in black circles.\n",
    "    ## Using the [1:-1] identifier to cut off the leading and trailing zeroes\n",
    "\n",
    "    ax.plot(tess_bjds[1:-1], pdcsap_fluxes[1:-1], 'k.', markersize=1)\n",
    "\n",
    "    # Center the x-axis on where we expect a transit to be (time = T0), and set\n",
    "    # the x-axis range within +/- 1 day of T0.\n",
    "    ########ax.set_xlim(t0 - 1.0, t0 + 1.0)\n",
    "\n",
    "    # Overplot a red vertical line that should be where the transit occurs.\n",
    "    ########ax.axvline(x=t0, color=\"red\")\n",
    "\n",
    "    # Let's label the axes and define a title for the figure.\n",
    "    fig.suptitle(CurrentLC())\n",
    "    ax.set_ylabel(\"PDCSAP Flux (e-/s)\")\n",
    "    ax.set_xlabel(\"Time (TBJD)\")\n",
    "\n",
    "    # Adjust the left margin so the y-axis label shows up.\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def LoadListGeneral(f):\n",
    "    lst=[]\n",
    "    try:\n",
    "        # Assuming everything CAN go well, do this\n",
    "        with open('./SIM_DATA/unpacked/{}'.format(f)) as df:\n",
    "            csvdf = csv.reader(df)\n",
    "            for lineholder in csvdf:\n",
    "                line = lineholder[0]                # I don't know why but this makes it work better\n",
    "                if line[0]!=\"#\":                    # Ignore commented lines (lines w/ FIRST STRING ELEMENT is a # character)\n",
    "                    lst.append(line.split()[0])       # Add line to list\n",
    "                # endif\n",
    "            # endfor\n",
    "        # endwith\n",
    "    except FileNotFoundError:\n",
    "        print(\"FNF\")\n",
    "        return\n",
    "    # end try\n",
    "    return lst\n",
    "\n",
    "def LoadList(itemtype=\"all\"):\n",
    "    \n",
    "    pl=\"tsop301_planet_data.txt\"\n",
    "    sl=\"tsop301_star_data.txt\"\n",
    "    ebl=\"tsop301_eb_data.txt\"\n",
    "    bebl=\"tsop301_backeb_data.txt\"\n",
    "    \n",
    "    foundflag=False\n",
    "    \n",
    "    # itemtype = (S)tar, (P)lanet, (E)clipsing (B)inary, or (B)ack (E)clipsing (B)inary\n",
    "    if itemtype.lower() in [\"s\", \"star\", \"all\"]:\n",
    "        foundflag = True\n",
    "        global starlist\n",
    "        starlist = LoadListGeneral(sl)\n",
    "        print(\"Loading star list: {}\".format(sl))\n",
    "    if itemtype.lower() in [\"p\", \"planet\", \"all\"]:\n",
    "        foundflag = True\n",
    "        global planetlist\n",
    "        planetlist = LoadListGeneral(pl)\n",
    "        print (\"loading planet list: {}\".format(pl))\n",
    "    if itemtype.lower() in [\"eb\", \"eclipsing binary\", \"eclipsingbinary\", \"all\"]:\n",
    "        foundflag = True\n",
    "        global eblist\n",
    "        eblist = LoadListGeneral(ebl)\n",
    "        print (\"loading eb list: {}\".format(ebl))\n",
    "    if itemtype.lower() in [\"beb\", \"back eclipsing binary\", \"backeclipsingbinary\", \"all\"]:\n",
    "        foundflag = True\n",
    "        global beblist\n",
    "        beblist = LoadListGeneral(bebl)\n",
    "        print (\"loading beb list: {}\".format(bebl))\n",
    "        \n",
    "    if foundflag:\n",
    "        global alllists\n",
    "        alllists = {\"s\": starlist, \"p\": planetlist, \"eb\": eblist, \"beb\": beblist}\n",
    "        return\n",
    "    else:\n",
    "        # If an invalid selection has been entered\n",
    "        print(\"You must enter either:\\n\"\n",
    "               \"* \\\"S\\\" (or \\\"Star\\\")\\n\"\n",
    "               \"* \\\"P\\\" (or \\\"Planet\\\")\\n\"\n",
    "               \"* \\\"EB\\\" (or \\\"Eclipsing Binary\\\")\\n\"\n",
    "               \"* \\\"BEB\\\" (or \\\"Back Eclipsing Binary\\\")\")\n",
    "        \n",
    "def IsThisAStar(n):\n",
    "    return n in alllists[\"s\"]\n",
    "    \n",
    "def IsThisAPlanet(n):\n",
    "    return n in alllists[\"p\"]\n",
    "\n",
    "def IsThisAEB(n):\n",
    "    return n in alllists[\"eb\"]\n",
    "\n",
    "def IsThisABEB(n):\n",
    "    return n in alllists[\"beb\"]\n",
    "\n",
    "# Function to tell you what an item is\n",
    "def WhatIsMyLC(n):\n",
    "    lbl = []\n",
    "    lbl.append(\"Star\") if IsThisAStar(n) else lbl\n",
    "    lbl.append(\"Planet\") if IsThisAPlanet(n) else lbl\n",
    "    lbl.append(\"EB\") if IsThisAEB(n) else lbl\n",
    "    lbl.append(\"BRB\") if IsThisABEB(n) else lbl\n",
    "    \n",
    "    return \"UNKNOWN\" if lbl==[] else lbl\n",
    "\n",
    "# Purely for convenience\n",
    "def CurrentLC():\n",
    "    return (\"File â„– {} - {}\".format(lastRandom[\"number\"], lastRandom[\"id\"]))\n",
    "\n",
    "def MakeDataSplit(lb,ub):\n",
    "    \"\"\"\n",
    "    Function designed to read a subsection of FITS files, and store them in a dataframe\n",
    "    This is designed to read only a certain amount, when reading all at once would crash the jupyter kernel.\n",
    "    \n",
    "    lb = lower bound\n",
    "    ub = upper bound\n",
    "    \n",
    "    EG: if lb=0 and ub=500, it will read the first 500 entries.    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Initiatate Dataframe\n",
    "    df = pd.DataFrame(columns=['id', 'vals', 'isplanet'])\n",
    "    \n",
    "    # Loop for each FITS file between Lower Bound (lb) and Upper Bound (ub)\n",
    "    for e, li in enumerate(tqdm(fitsList[lb:ub])):\n",
    "        #print(\"{}: Current File is {}\".format(e,li))\n",
    "        with fits.open (li, memmap=False) as f:\n",
    "            #Populate 'lastRandom' so store current number and id\n",
    "            GetRandomLC(e)\n",
    "            \n",
    "            # Get number and id\n",
    "            rnum = lastRandom[\"number\"]\n",
    "            rid = lastRandom[\"id\"]\n",
    "            dps = f[1].data['PDCSAP_FLUX'][1:-1]   #[1:-1] to omit the leading and trailing 0s present in all LCs in sample set\n",
    "            \n",
    "            try:\n",
    "                #add Data\n",
    "                df = df.append(pd.DataFrame([[rid,dps,IsThisAPlanet(rid)]], columns=['id', 'vals', 'isplanet']), ignore_index=True)\n",
    "            except ValueError:\n",
    "                print(\"THE FITS FILE {} DID NOT LOAD CORRECTLY AND AS SUCH WILL BE IGNORED\".format(e))\n",
    "        \n",
    "        \n",
    "        time.sleep(0.01)\n",
    "    return(df)\n",
    "\n",
    "def MakeDataJoin():\n",
    "    \"\"\"\n",
    "    A function to read all FITS files, in chunks, governed by variables below\n",
    "    \n",
    "    df = \n",
    "    m = max number of files to be read\n",
    "    s = split factor (how many to read at any one time)\n",
    "    c = loop counter\n",
    "    \n",
    "    It starts by making an array with (m/s, rounded up) entries, so each entry on the list can store each \"chunk\" of data.\n",
    "    This is done to prevent the Jupyter kernel crashing. Likely unnecessary if done via pure python but we're not, so screw it.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Make an empty list with enough space for all dataframes\n",
    "    m = int(len(fitsList))\n",
    "    s = 1000\n",
    "    c = 0\n",
    "    length = math.ceil(m/s)\n",
    "    dflist=[None] * length\n",
    "\n",
    "    for i in trange(c,m,s):\n",
    "        # CODE HERE\n",
    "        print(\"Loop {}: from {} to {}\".format(c,i,min((c+1)*s,m)), end='')\n",
    "        dflist[c] = MakeDataSplit(i,min((c+1)*s,m))\n",
    "        c += 1\n",
    "        #continue\n",
    "    print(\"Loop done; appending dataframe...\")\n",
    "    #dflist.append(tmp)\n",
    "    return (dflist)\n",
    "\n",
    "def MakeData():\n",
    "    ds = pd.concat(MakeDataJoin(), ignore_index=True)\n",
    "    return(ds)\n",
    "    \n",
    "# MAKE ME BIG DATAFRAME\n",
    "def MakeDataOld():\n",
    "    # Initiatate Dataframe\n",
    "    df = pd.DataFrame(columns=['id', 'vals', 'isplanet'])\n",
    "    \n",
    "    splitFactor = 5500\n",
    "    \n",
    "    # Loop for each FITS file\n",
    "    for e, li in enumerate(fitsList):\n",
    "        #print(\"{}: Current File is {}\".format(e,li))\n",
    "        with fits.open (li, memmap=False) as f:\n",
    "            #Populate 'lastRandom' so store current number and id\n",
    "            GetRandomLC(e)\n",
    "            \n",
    "            # Get number and id\n",
    "            rnum = lastRandom[\"number\"]\n",
    "            rid = lastRandom[\"id\"]\n",
    "            dps = f[1].data['PDCSAP_FLUX'][1:-1]   #[1:-1] to omit the leading and trailing 0s present in all LCs in sample set\n",
    "            \n",
    "            try:\n",
    "                #add Data\n",
    "                df = df.append(pd.DataFrame([[rid,dps,IsThisAPlanet(rid)]], columns=['id', 'vals', 'isplanet']), ignore_index=True)\n",
    "            except ValueError:\n",
    "                print(\"THE FITS FILE {} DID NOT LOAD CORRECTLY AND AS SUCH WILL BE IGNORED\".format(e))\n",
    "        \n",
    "        \n",
    "        time.sleep(0.01)\n",
    "    return(df)\n",
    "\n",
    "################################\n",
    "# RUN ALL INITIALISERS\n",
    "###\n",
    "def Initialise():\n",
    "    global fitsList\n",
    "    global dataset\n",
    "    print(\"Populating fitsList...\")\n",
    "    fitsList = MakingAList()\n",
    "    print(\"Loading the s/p/eb/beb Lists\")\n",
    "    LoadList()\n",
    "    print(\"Populating the DataFrame\")\n",
    "    dataset = MakeDataJoin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitsList = MakingAList()\n",
    "#LoadList()\n",
    "#len(fitsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating fitsList...\n",
      "Loading the s/p/eb/beb Lists\n",
      "Loading star list: tsop301_star_data.txt\n",
      "loading planet list: tsop301_planet_data.txt\n",
      "loading eb list: tsop301_eb_data.txt\n",
      "loading beb list: tsop301_backeb_data.txt\n",
      "Populating the DataFrame\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab6f595c4de45e58ffdfe1a29691928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 0: from 0 to 1000"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428eab3db6e24eb08cb5d5d95cbedbd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1: from 1000 to 2000"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46bffd07a794c678548c510c39c9d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 2: from 2000 to 3000"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96be69366254908a0eb4e5b32f415d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 3: from 3000 to 4000"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d80eaf01ecf4b4db5480601a33cf154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 4: from 4000 to 5000"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e689ac641c724fadaefc1539d51dd96e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 5: from 5000 to 6000"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10bc37e3b5944799e74f4196646c078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 6: from 6000 to 7000"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91244b7a23ad4075891f20d462716b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 7: from 7000 to 8000"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6dc4c41c8341289e7ed64501c19655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Initialise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
