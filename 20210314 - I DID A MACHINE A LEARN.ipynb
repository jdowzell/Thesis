{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load master-import.py\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "################################\n",
    "# Scientific imports\n",
    "###\n",
    "%matplotlib inline\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astroquery.mast import Observations\n",
    "from astroquery.mast import Catalogs\n",
    "\n",
    "###\n",
    "# General imports\n",
    "###\n",
    "import csv, math, io, os, os.path, sys, random\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from IPython.display import display\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,9)\n",
    "sb.set()\n",
    "\n",
    "###\n",
    "# Global Variables\n",
    "###\n",
    "# Lists\n",
    "fitsList=[]\n",
    "starlist=[]\n",
    "planetlist=[]\n",
    "eblist=[]\n",
    "beblist=[]\n",
    "dataset = pd.DataFrame(columns=['id', 'vals', 'isplanet'])\n",
    "\n",
    "# List Holder\n",
    "alllists = {}\n",
    "\n",
    "# Keep track of current LC and it's TIC identifier\n",
    "lastRandom={\n",
    "    \"number\": 0,\n",
    "    \"id\": 0\n",
    "}\n",
    "\n",
    "################################\n",
    "# Functions\n",
    "###\n",
    "# Function for Reading which LC datafiles we have into a list\n",
    "def MakingAList(prnt=False):\n",
    "    fl = []\n",
    "    fitsroot = \"SIM_DATA/\"\n",
    "    fits_directories = [x[0] for x in os.walk('./SIM_DATA/.', topdown=True)]\n",
    "\n",
    "    for fitsroot, fits_dirs, fits_files in os.walk(fitsroot):\n",
    "        for fits_file in fits_files:\n",
    "            fullpath = os.path.join(fitsroot, fits_file)\n",
    "            if (os.path.splitext(fullpath.lower())[1]).endswith('.fits'):\n",
    "                fl.append(fullpath)\n",
    "    if prnt==True:\n",
    "        print(\"Number of FITS files: {}\".format(len(fl)))\n",
    "    #print(len(fl))\n",
    "    return fl\n",
    "\n",
    "# Chooses a random number\n",
    "def GetRandomLC(n = None):\n",
    "    global lastRandom\n",
    "    #print(\"1: {}\".format(n))\n",
    "    if isinstance(n, int):\n",
    "        if 0 <= n < len(fitsList):\n",
    "            n = n\n",
    "        else:\n",
    "            n = random.randint(0,len(fitsList))\n",
    "    else:\n",
    "        n = random.randint(0,len(fitsList))\n",
    "    \n",
    "    lastRandom[\"number\"] = n\n",
    "    lastRandom[\"id\"] = str(fitsList[n].split(\"-\")[2].lstrip(\"0\"))\n",
    "    return n\n",
    "\n",
    "def DrawACurve(n=None):\n",
    "    rndFile = GetRandomLC() if n == None else GetRandomLC(n)\n",
    "    fitsFile = fitsList[rndFile]\n",
    "    \n",
    "    # The following line of code gives us the header values\n",
    "    fitsHeaders = fits.getheader(fitsFile)\n",
    "\n",
    "    with fits.open(fitsFile, mode=\"readonly\") as hdulist:\n",
    "\n",
    "        # Extract stellar parameters from the primary header.  We'll get the effective temperature, surface gravity,\n",
    "        # and TESS magnitude.\n",
    "        star_teff = hdulist[0].header['TEFF']\n",
    "        star_logg = hdulist[0].header['LOGG']\n",
    "        star_tmag = hdulist[0].header['TESSMAG']\n",
    "        obj = hdulist[0].header['OBJECT']\n",
    "        sector = hdulist[0].header['SECTOR']\n",
    "\n",
    "        # Extract some of the fit parameters for the first TCE.  These are stored in the FITS header of the first\n",
    "        # extension.\n",
    "        #period = hdulist[1].header['TPERIOD']\n",
    "        #duration = hdulist[1].header['TDUR']\n",
    "        duration = (hdulist[1].header['LIVETIME'])\n",
    "        #epoch = hdulist[1].header['TEPOCH']\n",
    "        #depth = hdulist[1].header['TDEPTH']\n",
    "\n",
    "        # Extract some of the columns of interest for the first TCE signal.  These are stored in the binary FITS table\n",
    "        # in the first extension.  We'll extract the timestamps in TBJD, phase, initial fluxes, and corresponding\n",
    "        # model fluxes.\n",
    "        #times = hdulist[1].data['TIME']\n",
    "        #phases = hdulist[1].data['PHASE']\n",
    "        #fluxes_init = hdulist[1].data['LC_INIT']\n",
    "        #model_fluxes_init = hdulist[1].data['MODEL_INIT']\n",
    "        tess_bjds = hdulist[1].data['TIME']\n",
    "        sap_fluxes = hdulist[1].data['SAP_FLUX']\n",
    "        pdcsap_fluxes = hdulist[1].data['PDCSAP_FLUX']\n",
    "\n",
    "    # Define the epoch of primary transit in TBJD.  Our timestamps are also already in TBJD.\n",
    "    #t0 = 1327.520678\n",
    "\n",
    "    # Start figure and axis.\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot the timeseries in black circles.\n",
    "    ## Using the [1:-1] identifier to cut off the leading and trailing zeroes\n",
    "\n",
    "    ax.plot(tess_bjds[1:-1], pdcsap_fluxes[1:-1], 'k.', markersize=1)\n",
    "\n",
    "    # Center the x-axis on where we expect a transit to be (time = T0), and set\n",
    "    # the x-axis range within +/- 1 day of T0.\n",
    "    ########ax.set_xlim(t0 - 1.0, t0 + 1.0)\n",
    "\n",
    "    # Overplot a red vertical line that should be where the transit occurs.\n",
    "    ########ax.axvline(x=t0, color=\"red\")\n",
    "\n",
    "    # Let's label the axes and define a title for the figure.\n",
    "    fig.suptitle(CurrentLC())\n",
    "    ax.set_ylabel(\"PDCSAP Flux (e-/s)\")\n",
    "    ax.set_xlabel(\"Time (TBJD)\")\n",
    "\n",
    "    # Adjust the left margin so the y-axis label shows up.\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    #plt.figure(figsize=(2,8))\n",
    "    plt.show()\n",
    "    \n",
    "def LoadListGeneral(f):\n",
    "    lst=[]\n",
    "    try:\n",
    "        # Assuming everything CAN go well, do this\n",
    "        with open('./SIM_DATA/unpacked/{}'.format(f)) as df:\n",
    "            csvdf = csv.reader(df)\n",
    "            for lineholder in csvdf:\n",
    "                line = lineholder[0]                # I don't know why but this makes it work better\n",
    "                if line[0]!=\"#\":                    # Ignore commented lines (lines w/ FIRST STRING ELEMENT is a # character)\n",
    "                    lst.append(line.split()[0])       # Add line to list\n",
    "                # endif\n",
    "            # endfor\n",
    "        # endwith\n",
    "    except FileNotFoundError:\n",
    "        print(\"FNF\")\n",
    "        return\n",
    "    # end try\n",
    "    return lst\n",
    "\n",
    "def LoadList(itemtype=\"all\"):\n",
    "    \n",
    "    pl=\"tsop301_planet_data.txt\"\n",
    "    sl=\"tsop301_star_data.txt\"\n",
    "    ebl=\"tsop301_eb_data.txt\"\n",
    "    bebl=\"tsop301_backeb_data.txt\"\n",
    "    \n",
    "    foundflag=False\n",
    "    \n",
    "    # itemtype = (S)tar, (P)lanet, (E)clipsing (B)inary, or (B)ack (E)clipsing (B)inary\n",
    "    if itemtype.lower() in [\"s\", \"star\", \"all\"]:\n",
    "        foundflag = True\n",
    "        global starlist\n",
    "        starlist = LoadListGeneral(sl)\n",
    "        print(\"Loading star list: {}\".format(sl))\n",
    "    if itemtype.lower() in [\"p\", \"planet\", \"all\"]:\n",
    "        foundflag = True\n",
    "        global planetlist\n",
    "        planetlist = LoadListGeneral(pl)\n",
    "        print (\"loading planet list: {}\".format(pl))\n",
    "    if itemtype.lower() in [\"eb\", \"eclipsing binary\", \"eclipsingbinary\", \"all\"]:\n",
    "        foundflag = True\n",
    "        global eblist\n",
    "        eblist = LoadListGeneral(ebl)\n",
    "        print (\"loading eb list: {}\".format(ebl))\n",
    "    if itemtype.lower() in [\"beb\", \"back eclipsing binary\", \"backeclipsingbinary\", \"all\"]:\n",
    "        foundflag = True\n",
    "        global beblist\n",
    "        beblist = LoadListGeneral(bebl)\n",
    "        print (\"loading beb list: {}\".format(bebl))\n",
    "        \n",
    "    if foundflag:\n",
    "        global alllists\n",
    "        alllists = {\"s\": starlist, \"p\": planetlist, \"eb\": eblist, \"beb\": beblist}\n",
    "        return\n",
    "    else:\n",
    "        # If an invalid selection has been entered\n",
    "        print(\"You must enter either:\\n\"\n",
    "               \"* \\\"S\\\" (or \\\"Star\\\")\\n\"\n",
    "               \"* \\\"P\\\" (or \\\"Planet\\\")\\n\"\n",
    "               \"* \\\"EB\\\" (or \\\"Eclipsing Binary\\\")\\n\"\n",
    "               \"* \\\"BEB\\\" (or \\\"Back Eclipsing Binary\\\")\")\n",
    "        \n",
    "def IsThisAStar(n):\n",
    "    return n in alllists[\"s\"]\n",
    "    \n",
    "def IsThisAPlanet(n):\n",
    "    return n in alllists[\"p\"]\n",
    "\n",
    "def IsThisAEB(n):\n",
    "    return n in alllists[\"eb\"]\n",
    "\n",
    "def IsThisABEB(n):\n",
    "    return n in alllists[\"beb\"]\n",
    "\n",
    "# Function to tell you what an item is\n",
    "def WhatIsMyLC(n):\n",
    "    lbl = []\n",
    "    lbl.append(\"Star\") if IsThisAStar(n) else lbl\n",
    "    lbl.append(\"Planet\") if IsThisAPlanet(n) else lbl\n",
    "    lbl.append(\"EB\") if IsThisAEB(n) else lbl\n",
    "    lbl.append(\"BRB\") if IsThisABEB(n) else lbl\n",
    "    \n",
    "    return \"UNKNOWN\" if lbl==[] else lbl\n",
    "\n",
    "# Purely for convenience\n",
    "def CurrentLC():\n",
    "    return (\"File â„– {} - {}\".format(lastRandom[\"number\"], lastRandom[\"id\"]))\n",
    "    \n",
    "# MAKE ME BIG DATAFRAME\n",
    "def MakeData():\n",
    "    \n",
    "    # Initiatate Dataframe\n",
    "    df = pd.DataFrame(columns=['id', 'vals', 'isplanet'])\n",
    "    \n",
    "    # Loop for each FITS file\n",
    "    for e, li in enumerate(fitsList[:101].copy()):\n",
    "        with fits.open (li, memmap=False) as f:\n",
    "            #Populate 'lastRandom' so store current number and id\n",
    "            GetRandomLC(e)\n",
    "            \n",
    "            # Get number and id\n",
    "            rnum = lastRandom[\"number\"]\n",
    "            rid = lastRandom[\"id\"]\n",
    "            \n",
    "            #add Data\n",
    "            df = df.append(pd.DataFrame([[rid,f[1].data['PDCSAP_FLUX'][1:-1],IsThisAPlanet(rid)]], columns=['id', 'vals', 'isplanet']), ignore_index=True)\n",
    "            #df = df.append(pd.DataFrame([[rid,'LOLE',IsThisAPlanet(rid)]], columns=['id', 'vals', 'isplanet']), ignore_index=True)\n",
    "    return(df)\n",
    "\n",
    "################################\n",
    "# RUN ALL INITIALISERS\n",
    "###\n",
    "def Initialise():\n",
    "    global fitsList\n",
    "    global dataset\n",
    "    print(\"Populating fitsList...\")\n",
    "    fitsList = MakingAList()\n",
    "    print(\"Loading the s/p/eb/beb Lists\")\n",
    "    LoadList()\n",
    "    print(\"Populating the DataFrame\")\n",
    "    dataset = MakeData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating fitsList...\n",
      "Loading the s/p/eb/beb Lists\n",
      "Loading star list: tsop301_star_data.txt\n",
      "loading planet list: tsop301_planet_data.txt\n",
      "loading eb list: tsop301_eb_data.txt\n",
      "loading beb list: tsop301_backeb_data.txt\n",
      "Populating the DataFrame\n"
     ]
    }
   ],
   "source": [
    "Initialise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [179952.0, 179979.34, 179668.58, 179833.98, 17...\n",
       "1      [21610.824, 21618.32, 21631.969, 21623.95, 216...\n",
       "2      [108729.734, 108670.54, 108613.875, 108629.734...\n",
       "3      [56039.613, 56027.977, 55994.34, 55974.965, 56...\n",
       "4      [18019.508, 17992.531, 17918.803, 18050.266, 1...\n",
       "                             ...                        \n",
       "96     [6429.8755, 6417.58, 6425.976, 6428.759, 6433....\n",
       "97     [33687.33, 33695.26, 33713.566, 33670.67, 3367...\n",
       "98     [8813.81, 8802.651, 8807.448, 8780.694, 8820.8...\n",
       "99     [3135.4832, 3158.8599, 3145.7952, 3146.2546, 3...\n",
       "100    [1875865.1, 1876130.9, 1877120.5, 1875987.9, 1...\n",
       "Name: vals, Length: 101, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['vals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4078971c512144e4a78e2693b9b21df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm, trange\n",
    "import time    # to be used in loop iterations\n",
    "\n",
    "for i in range(100):\n",
    "    pass\n",
    "\n",
    "# Loop with a progress bar\n",
    "for i in trange(100):\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38558e7121ed4f21b73a2768800517e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vals</th>\n",
       "      <th>isplanet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, vals, isplanet]\n",
       "Index: []"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def MakeDataBar():\n",
    "    \n",
    "    # Initiatate Dataframe\n",
    "    df = pd.DataFrame(columns=['id', 'vals', 'isplanet'])\n",
    "    \n",
    "    # Loop for each FITS file\n",
    "    for e, li in enumerate(tqdm(fitsList[1370:1400])):\n",
    "        print(\"{}: Current File is {}\".format((e+1370),li))\n",
    "        with fits.open (li, memmap=False) as f:\n",
    "            #Populate 'lastRandom' so store current number and id\n",
    "            GetRandomLC(e)\n",
    "            \n",
    "            # Get number and id\n",
    "            rnum = lastRandom[\"number\"]\n",
    "            rid = lastRandom[\"id\"]\n",
    "            \n",
    "            #add Data\n",
    "            df = df.append(pd.DataFrame([[rid,f[1].data['PDCSAP_FLUX'][1:-1],IsThisAPlanet(rid)]], columns=['id', 'vals', 'isplanet']), ignore_index=True)\n",
    "            #df = df.append(pd.DataFrame([[rid,'LOLE',IsThisAPlanet(rid)]], columns=['id', 'vals', 'isplanet']), ignore_index=True)\n",
    "        #time.sleep(0.0001)\n",
    "    return(df)\n",
    "MakeDataBar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error seems to be in file `SIM_DATA/tess2018191215100-s0001-0000000177165931-0001-a_lc.fits` (file ID:1380, or the 1381st file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: SIM_DATA/tess2018191215100-s0001-0000000177165931-0001-a_lc.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU      44   ()      \n",
      "  1  LIGHTCURVE    1 BinTableHDU    158   20340R x 20C   [D, E, J, E, E, E, E, E, E, J, D, E, D, E, D, E, D, E, E, E]   \n"
     ]
    }
   ],
   "source": [
    "errFile=\"SIM_DATA/tess2018191215100-s0001-0000000177165931-0001-a_lc.fits\"\n",
    "tstFile=\"SIM_DATA/tess2018191215100-s0001-0000000364110868-0001-a_lc.fits\"\n",
    "fits.info(errFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: SIM_DATA/tess2018191215100-s0001-0000000364110868-0001-a_lc.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU      44   ()      \n",
      "  1  LIGHTCURVE    1 BinTableHDU    167   20340R x 20C   [D, E, J, E, E, E, E, E, E, J, D, E, D, E, D, E, D, E, E, E]   \n",
      "  2  APERTURE      1 ImageHDU        49   (11, 11)   int32   \n"
     ]
    }
   ],
   "source": [
    "fits.info(tstFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0.    52433.04  52440.36  ... 52402.484 52398.266     0.   ]\n"
     ]
    }
   ],
   "source": [
    "with fits.open(tstFile) as hdu:\n",
    "    print(hdu[1].data['PDCSAP_FLUX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PDCSAP_FLUX'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'PDCSAP_FLUX'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fits.getheader(tstFile, ext=1)['TTYPE8'];\n",
    "fits.getheader(errFile, ext=1)['TTYPE8']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for some reason, it doesn't like this curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
